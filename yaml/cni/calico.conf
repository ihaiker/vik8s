namespace: kube-system;

configmap calico-config {
    # Typha is disabled.
    typha_service_name: "none";

    # Configure the backend to use.
    calico_backend: "bird";

    # Configure the MTU to use for workload interfaces and the
    # tunnels.  For IPIP, set to your network MTU - 20; for VXLAN
    # set to your network MTU - 50.
    veth_mtu: "'{{.MTU}}'";

    # The CNI network configuration to install on each node.  The special
    # values in this config will be automatically populated.
    cni_network_config: '
        {
          "name": "k8s-pod-network",
          "cniVersion": "0.3.1",
          "plugins": [
            {
              "type": "calico",
              "log_level": "warn",
              "datastore_type": "kubernetes",
              "nodename": "__KUBERNETES_NODE_NAME__",
              "mtu": __CNI_MTU__,
              "ipam": {
                  "type": "calico-ipam"
              },
              "policy": {
                  "type": "k8s"
              },
              "kubernetes": {
                  "kubeconfig": "__KUBECONFIG_FILEPATH__"
              }
            },
            {
              "type": "portmap",
              "snat": true,
              "capabilities": {"portMappings": true}
            },
            {
              "type": "bandwidth",
              "capabilities": {"bandwidth": true}
            }
          ]
        }
    ';
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 bgpconfigurations.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: BGPConfiguration;
        plural: bgpconfigurations;
        singular: bgpconfiguration;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 bgppeers.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: BGPPeer;
        plural: bgppeers;
        singular: bgppeer;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 blockaffinities.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: BlockAffinity;
        plural: blockaffinities;
        singular: blockaffinity;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 clusterinformations.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: ClusterInformation;
        plural: clusterinformations;
        singular: clusterinformation;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 felixconfigurations.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: FelixConfiguration;
        plural: felixconfigurations;
        singular: felixconfiguration;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 globalnetworkpolicies.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: GlobalNetworkPolicy;
        plural: globalnetworkpolicies;
        singular: globalnetworkpolicy;
        shortNames: gnp;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 globalnetworksets.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: GlobalNetworkSet;
        plural: globalnetworksets;
        singular: globalnetworkset;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 hostendpoints.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: HostEndpoint;
        plural: hostendpoints;
        singular: hostendpoint;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 ipamblocks.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: IPAMBlock;
        plural: ipamblocks;
        singular: ipamblock;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 ipamconfigs.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: IPAMConfig;
        plural: ipamconfigs;
        singular: ipamconfig;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 ipamhandles.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: IPAMHandle;
        plural: ipamhandles;
        singular: ipamhandle;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 ippools.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: IPPool;
        plural: ippools;
        singular: ippool;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 kubecontrollersconfigurations.crd.projectcalico.org {
    scope: Cluster;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: KubeControllersConfiguration;
        plural: kubecontrollersconfigurations;
        singular: kubecontrollersconfiguration;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 networkpolicies.crd.projectcalico.org {
    scope: Namespaced;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: NetworkPolicy;
        plural: networkpolicies;
        singular: networkpolicy;
    }
}

CustomResourceDefinition:apiextensions.k8s.io/v1beta1 networksets.crd.projectcalico.org {
    scope: Namespaced;
    group: crd.projectcalico.org;
    version: v1;
    names {
        kind: NetworkSet;
        plural: networksets;
        singular: networkset;
    }
}

# Include a clusterrole for the kube-controllers component,
# and bind it to the calico-kube-controllers serviceaccount.
ClusterRole:rbac.authorization.k8s.io/v1 calico-kube-controllers {
    rules {
        apiGroups: "";
        resources: nodes;
        verbs: watch list get;
    }
    rules {
        apiGroups: "";
        resources: pods;
        verbs: get;
    }
    rules {
        apiGroups "crd.projectcalico.org";
        resources: ippools;
        verbs: list;
    }
    rules {
        apiGroups "crd.projectcalico.org"
        resources: blockaffinities ipamblocks ipamhandles;
        verbs: get list create update delete;
    }
    # kube-controllers manages hostendpoints.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: hostendpoints;
        verbs: get list create update delete;
    }
    # Needs access to update clusterinformations.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: clusterinformations;
        verbs: get create update;
    }
    # KubeControllersConfiguration is where it gets its config
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: kubecontrollersconfigurations;
        verbs: get create update watch;
    }
}

ClusterRoleBinding:rbac.authorization.k8s.io/v1 calico-kube-controllers {
    roleRef {
        apiGroup: rbac.authorization.k8s.io;
        kind: ClusterRole;
        name: calico-kube-controllers;
    }
    subjects {
        kind: ServiceAccount;
        name: calico-kube-controllers;
        namespace: kube-system;
    }
}

# Include a clusterrole for the calico-node DaemonSet,
# and bind it to the calico-node serviceaccount.
ClusterRole:rbac.authorization.k8s.io/v1 calico-node {
    # The CNI plugin needs to get pods, nodes, and namespaces.
    rules {
        apiGroups: "";
        resources: pods nodes namespaces;
        verbs: get;
    }
    rules {
        apiGroups: "";
        resources: endpoints services;
        verbs: watch list get;
    }
    rules {
        apiGroups: "";
        resources: configmaps;
        verbs: get;
    }
    rules {
        apiGroups: "";
        resources: "nodes/status";
        verbs: patch update;
    }
    rules {
        apiGroups: "networking.k8s.io";
        resources: networkpolicies;
        verbs: watch list;
    }
    # Used by Calico for policy information.
    rules {
        apiGroups: "";
        resources: pods namespaces serviceaccounts;
        verbs: list watch;
    }
    # The CNI plugin patches pods/status.
    rules {
        apiGroups: "";
        resources: "pods/status";
        verbs: patch;
    }

    # Calico monitors various CRDs for config.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: globalfelixconfigs felixconfigurations bgppeers globalbgpconfigs bgpconfigurations
            ippools ipamblocks globalnetworkpolicies globalnetworksets networkpolicies
            networksets clusterinformations hostendpoints blockaffinities;
        verbs: get list watch;
    }
    # Calico must create and update some CRDs on startup.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: ippools felixconfigurations clusterinformations;
        verbs: create update;
    }
    # Calico stores some configuration information on the node.
    rules {
        apiGroups: "";
        resources: nodes;
        verbs: get list watch;
    }
    # These permissions are only requried for upgrade from v2.6, and can
    # be removed after upgrade or on fresh installations.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: bgpconfigurations bgppeers;
        verbs: create update;
    }
    # These permissions are required for Calico CNI to perform IPAM allocations.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: blockaffinities ipamblocks ipamhandles;
        verbs: get list create update delete;
    }
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: ipamconfigs;
        verbs: get;
    }
    # Block affinities must also be watchable by confd for route aggregation.
    rules {
        apiGroups: "crd.projectcalico.org";
        resources: blockaffinities;
        verbs: watch;
    }
    # The Calico IPAM migration needs to get daemonsets. These permissions can be
    # removed if not upgrading from an installation using host-local IPAM.
    rules {
        apiGroups: "apps";
        resources: daemonsets;
        verbs: get;
    }
}

ClusterRoleBinding:rbac.authorization.k8s.io/v1 calico-node {
    roleRef {
        apiGroup: rbac.authorization.k8s.io;
        kind: ClusterRole;
        name: calico-node;
    }
    subjects {
        kind: ServiceAccount;
        name: calico-node;
        namespace: kube-system;
    }
}


# Source: calico/templates/calico-node.yaml
# This manifest installs the calico-node container, as well
# as the CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
DaemonSet calico-node {
    # This, along with the CriticalAddonsOnly toleration below,
    # marks the pod as a critical add-on, ensuring it gets
    # priority scheduling and that its resources are reserved
    # if it ever gets evicted.
    annotations {
        scheduler.alpha.kubernetes.io/critical-pod: '';
    }

    updateStrategy {
        type: RollingUpdate;
        rollingUpdate: maxUnavailable=1;
    }

    nodeSelector {
        kubernetes.io/os: linux;
    }
    hostNetwork: true;

    tolerations effect=NoSchedule operator=Exists;
    tolerations key=CriticalAddonsOnly operator=Exists;
    tolerations effect=NoExecute operator=Exists;

    serviceAccountName: calico-node;
    terminationGracePeriodSeconds: 0;
    priorityClassName: system-node-critical;

    initContainer set-networkmanager "{{.Repo}}calico/cni:{{.Version}}" IfNotPresent {
        securityContext privileged=true;
        command "/bin/sh" "-c"
        "echo -e '[keyfile]\nunmanaged-devices=interface-name:cali*;interface-name:tunl*' > /etc/NetworkManager/conf.d/calico.conf";
        mount hostPath:network-manager-dir /etc/NetworkManager/conf.d;
    }

    # This container performs upgrade from host-local IPAM to calico-ipam.
    # It can be deleted if this is a fresh installation, or if you have already
    # upgraded to use calico-ipam.
    initContainer upgrade-ipam "{{.Repo}}calico/cni:{{.Version}}" {
        securityContext privileged=true;
        command: "/opt/cni/bin/calico-ipam" "-upgrade";
        envs {
            KUBERNETES_NODE_NAME field spec.nodeName;
            CALICO_NETWORKING_BACKEND configMap calico-config calico_backend;
        }
        mounts {
            hostPath:host-local-net-dir /var/lib/cni/networks;
            hostPath:cni-bin-dir /opt/cni/bin:/host/opt/cni/bin;
        }
    }

    # This container installs the CNI binaries
    # and CNI network config file on each node.
    initContainer install-cni "{{.Repo}}calico/cni:{{.Version}}" {
        securityContext privileged=true;
        command: "/install-cni.sh";
        envs {
            CNI_CONF_NAME 10-calico.conflist;
            CNI_NETWORK_CONFIG configMap calico-config cni_network_config;
            KUBERNETES_NODE_NAME field spec.nodeName;
            CNI_MTU configMap calico-config veth_mtu;
            SLEEP false;
        }
        mount hostPath:cni-bin-dir /opt/cni/bin:/host/opt/cni/bin;
        mount hostPath:cni-net-dir /etc/cni/net.d:/host/etc/cni/net.d;
    }

    # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes
    # to communicate with Felix over the Policy Sync API.
    initContainer flexvol-driver "{{.Repo}}calico/pod2daemon-flexvol:{{.Version}}" {
        securityContext privileged=true;
        mount hostPath:flexvol-driver-host
            /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds:/host/driver
            DirectoryOrCreate;
    }

    # Runs calico-node container on each Kubernetes node.  This
    # container programs network policy and routes on each host.
    container  calico-node "{{.Repo}}calico/node:{{.Version}}" {
        envs {
            # Use Kubernetes API as the backing datastore.
            DATASTORE_TYPE kubernetes;
            WAIT_FOR_DATASTORE true;
            NODENAME field spec.nodeName;
            CALICO_NETWORKING_BACKEND configMap calico-config calico_backend;

            # Cluster type to identify the deployment type
            CLUSTER_TYPE "k8s,bgp";
            # Auto-detect the BGP IP address.
            IP: "autodetect";
            IP_AUTODETECTION_METHOD: "interface={{ .Interface }}";
            CALICO_IPV4POOL_IPIP: "{{if not .IPIP }}Off{{else}}Always{{end}}";

            # Set MTU for tunnel device used if ipip is enabled
            FELIX_IPINIPMTU configMap calico-config veth_mtu;

            # Set MTU for the VXLAN tunnel device.
            FELIX_VXLANMTU configMap calico-config veth_mtu;

            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within `--cluster-cidr`.
            CALICO_IPV4POOL_CIDR: "{{ .CIDR }}";
            CALICO_DISABLE_FILE_LOGGING: true;

            # Set Felix endpoint to host default action to ACCEPT.
            FELIX_DEFAULTENDPOINTTOHOSTACTION "ACCEPT";

            # Disable IPv6 on Kubernetes.
            FELIX_IPV6SUPPORT: "false";

            # Set Felix logging to "info"
            FELIX_LOGSEVERITYSCREEN: "warn";
            FELIX_HEALTHENABLED: "true";
        }

        resources {
            requests cpu=250m;
        }

        livenessProbe {
            exec {
                command: "/bin/calico-node" "-felix-live" "-bird-live";
            }
            periodSeconds: 10;
            initialDelaySeconds: 10;
            failureThreshold: 6;
        }
        readinessProbe {
            exec {
                command: "/bin/calico-node" "-felix-ready" "-bird-ready";
            }
            periodSeconds: 10;
        }

        mounts {
            hostPath:lib-modules /lib/modules {
                readOnly true;
            }
            hostPath:xtables-lock /run/xtables.lock FileOrCreate;
            hostPath:var-run-calico /var/run/calico;
            hostPath:var-lib-calico /var/lib/calico;
            hostPath:policysync /var/run/nodeagent DirectoryOrCreate;
        }
    }
}

ServiceAccount:v1 calico-node;

deployment calico-kube-controllers {
    replicas: 1;
    strategy type=Recreate;
    nodeSelector {
        kubernetes.io/os: linux;
    }
    tolerations: key=CriticalAddonsOnly operator=Exists;
    tolerations key=node-role.kubernetes.io/master effect=NoSchedule;

    serviceAccountName: calico-kube-controllers;
    priorityClassName: system-cluster-critical;

    template {
        metadata {
            annotations {
                scheduler.alpha.kubernetes.io/critical-pod "";
            }
        }
    }
    container calico-kube-controllers "{{.Repo}}calico/kube-controllers:{{.Version}}" {
        env ENABLED_CONTROLLERS node;
        env DATASTORE_TYPE kubernetes;
        readinessProbe {
            exec {
                command: "/usr/bin/check-status" "-r";
            }
        }
    }
}

ServiceAccount:v1 calico-kube-controllers;